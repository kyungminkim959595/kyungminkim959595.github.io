<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> How Does Classifier-free Guidance Amplify the Societal Bias in Text-to-image Diffusion Models? | Efficient ML Systems (EECE695E) Blog Post </title> <meta name="author" content="You R. Name"> <meta name="description" content="Literature review and empirical analyses on the bias amplification in CFG for diffusion models"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kyungminkim959595.github.io/blog/2025/cfg-bias/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.9.4/dist/leaflet.min.css" integrity="sha256-q9ba7o845pMPFU+zcAll8rv+gC+fSovKsOoNQ6cynuQ=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/styles/github.min.css" integrity="sha256-Oppd74ucMR5a5Dq96FxjEzGF7tTw2fZ/6ksAqDCM8GY=" crossorigin="anonymous" media="screen and (prefers-color-scheme: light)"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/styles/github-dark.min.css" integrity="sha256-nyCNAiECsdDHrr/s2OQsp5l9XeY2ZJ0rMepjCT2AkBk=" crossorigin="anonymous" media="screen and (prefers-color-scheme: dark)"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/diff2html@3.4.47/bundles/css/diff2html.min.css" integrity="sha256-IMBK4VNZp0ivwefSn51bswdsrhk0HoMTLc2GqFHFBXg=" crossorigin="anonymous"> <link defer rel="stylesheet" type="text/css" href="https://tikzjax.com/v1/fonts.css"> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "How Does Classifier-free Guidance Amplify the Societal Bias in Text-to-image Diffusion Models?",
            "description": "Literature review and empirical analyses on the bias amplification in CFG for diffusion models",
            "published": "May 27, 2025",
            "authors": [
              
              {
                "author": "Myeongsoo Kim",
                "authorURL": "https://ime.postech.ac.kr/",
                "affiliations": [
                  {
                    "name": "Industrial Management and Engineering, POSTECH",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Kyungmin Kim",
                "authorURL": "https://ai.postech.ac.kr/",
                "affiliations": [
                  {
                    "name": "Graduate School of Artificial Intelligence, POSTECH",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Efficient ML Systems (EECE695E) Blog Post </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>How Does Classifier-free Guidance Amplify the Societal Bias in Text-to-image Diffusion Models?</h1> <p>Literature review and empirical analyses on the bias amplification in CFG for diffusion models</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#group-fairness-and-bias-amplification-in-generative-models">Group Fairness and Bias Amplification in Generative Models</a> </div> <ul> <li> <a href="#group-fairness-in-generative-models">Group Fairness in Generative Models</a> </li> <li> <a href="#bias-amplification-in-generative-models">Bias Amplification in Generative Models</a> </li> <li> <a href="#demographic-bias-in-text-to-image-diffusion-models">Demographic Bias in Text-to-image Diffusion Models</a> </li> <li> <a href="#bias-evaluation-in-text-to-image-diffusion-models">Bias Evaluation in Text-to-image Diffusion Models</a> </li> </ul> <div> <a href="#bias-ampliification-in-classifier-free-guidance-for-diffusion-models">Bias Ampliification in Classifier-free Guidance for Diffusion Models</a> </div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <h3 id="motivation">Motivation</h3> <p>Text-to-image (T2I) diffusion models have remarkable capabilities in generating realistic images from input text. (Naik &amp; Nushi, 2023) However, there are growing concerns about their tendency to produce biased images toward specific demographic groups ex) gender bias, skin tone bias, attribute bias, …. Because large-scale datasets encode these social biases and diffusion models learn from that distribution, they tend to generate biased images toward specific demographic groups. We address the bias amplification phenomenon such that a model’s outputs exhibit stronger biases than those present in its training data like figure 1.</p> <div class="row justify-content-sm-center"> <div class="col-sm-10 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cfg_ba/ba_figure-480.webp 480w,/assets/img/cfg_ba/ba_figure-800.webp 800w,/assets/img/cfg_ba/ba_figure-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cfg_ba/ba_figure.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Figure 1. The Bias Amplification Paradox in Text-to-Image Generation" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Which factors drive bias amplification in T2I diffusion models? We pinpoint Classifier-Free Guidance (CFG)—universally applied during T2I diffusion model generation—as a potential contributor. While CFG substantially improves image fidelity and alignment with the conditioning prompt, elevating its strength inherently diminishes sample diversity and biases generation toward prototypical outputs. In practice, users typically operate in the higher guidance‐scale range, adjusting the parameter to obtain their desired images.</p> <p>Recently, Kim et al. (2024) empirically demonstrated that higher CFG scales correspond to an increased prevalence of majority-group attributes, thereby identifying CFG intensity as a direct mechanism of bias amplification.</p> <p>\figure 2</p> <p>In this blog post, we analyze how Classifier‐Free Guidance (CFG) drives bias amplification in text‐to‐image diffusion models. Our work proceeds in three steps: (1) we formulate the problem by surveying prior research on CFG’s impact on model distributions; (2) we quantitatively assess the degree to which CFG contributes to bias amplification; and (3) we characterize the relationship between guidance scale and bias trends. We conducted our experimental analysis on the gender–occupation bias, a primary focus in fairness studies of text-to-image generative models.</p> <table> <tbody> <tr> <td>Based on these findings, we argue that—unlike mainstream efforts aimed at enforcing fairness in the conditional distribution p(x</td> <td>y) —future research must target fairness in the reverse conditional p(y</td> <td>x), particularly under low‐temperature sampling regimes.</td> </tr> </tbody> </table> <hr> <h2 id="preliminary">Preliminary</h2> <h3 id="group-fairness-and-bias-amplification">Group Fairness and Bias amplification</h3> <h3 id="diffusion-model-and-classifier-free-guidance">Diffusion Model and Classifier-free guidance</h3> <p>Recent diffusion models belong to the family of score-based generative models and are formulated within the stochastic differential equation (SDE) framework.</p> <p>figure 3</p> <p>The forward process refers to perturbing the data distribution via a diffusion process. As indicated by the symmetric coloring of the density-representing boxes in the figure, the reverse process reconstructs the marginal distributions of the forward process at each time step. To generate images, one must solve the reverse SDE, which therefore requires an accurate estimate of the score function.</p> <p>Classifier-free guidance(CFG) is a sampling strategy that employs an extrapolated score toward the conditional distribution, controlled by the guidance scale w, as follows. It pushes samples in the direction of higher p(c \mid x), but it does not directly correspond to the distribution p_w.</p> <p>p</p> <p>Here, it is important to note that the sampling distribution has deviated from the original data distribution. Bias amplification refers to the phenomenon in which a diffusion model’s sample distribution—expected in theory to follow the data distribution—actually exhibits an exacerbated bias. By applying CFG, however, the intended sampling distribution is inherently shifted from the pure data distribution to one weighted by both p(y∣x) and the guidance scale w.</p> <p>Furthermore, we demonstrated in a simple setup (see Figure 4) that this shift acts to amplify bias in gender-occupation fairness. While the unconditional distribution corresponds to a single marginal distribution, the conditional distribution can exhibit higher or lower densities for specific groups depending on the conditioning variable y.</p> <p>figure 3</p> <p>In the Experiments section, we empirically demonstrate that this tendency can indeed be observed in both text-to-image diffusion models and a toy example.</p> <hr> <h2 id="experiment">Experiment</h2> <h3 id="t2i-diffusion-model--stable-diffusion">T2I diffusion model : Stable diffusion</h3> <h3 id="class-conditional-diffusion-model">Class conditional diffusion model</h3> <hr> <h2 id="discussion">Discussion</h2> <p>In this blog post, we empirically assessed the impact of CFG on bias amplification in T2I diffusion models, demonstrating that CFG amplifies bias by extrapolating</p> <p>the conditional distribution further away from the unconditional distribution.</p> <p>The limitations not addressed in this post are as follows:</p> <ul> <li>The numerical values cannot be considered strictly precise because our evaluation operates on high-dimensional, complex text-conditioned distributions.</li> <li>Images generated at low guidance scales often fail to form properly, making those measurements less reliable. Since we assigned gender by mapping each image to the closest class using a CLIP classifier, the CLIP model’s own biases may have influenced our results.</li> </ul> <p>To address these, we validated the observed trends using toy examples.</p> <p>Through this blog post, we emphasize that group-fairness research for diffusion models must address the effects of CFG, and more broadly, that debiasing low-temperature sampling strategies is essential for generative models.</p> <ul> <li>In most of the papers I reviewed, there is little to no discussion of CFG’s impact, and their experimental setups are often missed.</li> <li>Kim et al. (2024), who previously identified the same problem, proposed a solution that attenuates bias in the text-condition embeddings of the text-conditional component. We approached the problem from a slightly different angle, framing it as the disparity in bias levels for the attribute between the conditional distribution and the unconditional distribution.</li> <li>Our proposal is to reduce this disparity, and we believe that one promising direction is to leverage Autoguidance—one of the recent state-of-the-art CFG methods. This methodology leverages the conditional distribution of a weaker model rather than the unconditional distribution. However, it still does not resolve which weaker model should be employed within T2I diffusion frameworks, necessitating further research.</li> </ul> <p>We have always considered fairness only with respect to $p(x \mid y)$, but for practical applications, fairness in $p(y \mid x)$ must also be taken into account.</p> <hr> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2025-05-27-cfg-bias.bib"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 You R. Name. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/mermaid@10.7.0/dist/mermaid.min.js" integrity="sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js" integrity="sha256-1rA678n2xEx7x4cTZ5x4wpUCj6kUMZEZ5cxLSVSFWxw=" crossorigin="anonymous"></script> <script defer src="/assets/js/mermaid-setup.js?38ca0a0126f7328d2d9a46bad640931f" type="text/javascript"></script> <script src="https://cdn.jsdelivr.net/npm/diff2html@3.4.47/bundles/js/diff2html-ui.min.js" integrity="sha256-eU2TVHX633T1o/bTQp6iIJByYJEtZThhF9bKz/DcbbY=" crossorigin="anonymous"></script> <script defer src="/assets/js/diff2html-setup.js?80a6e52ce727518bbd3aed2bb6ba5601" type="text/javascript"></script> <script src="https://cdn.jsdelivr.net/npm/leaflet@1.9.4/dist/leaflet.min.js" integrity="sha256-MgH13bFTTNqsnuEoqNPBLDaqxjGH+lCpqrukmXc8Ppg=" crossorigin="anonymous"></script> <script defer src="/assets/js/leaflet-setup.js?b6313931e203b924523e2d8b75fe8874" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/chart.js@4.4.1/dist/chart.umd.min.js" integrity="sha256-0q+JdOlScWOHcunpUk21uab1jW7C1deBQARHtKMcaB4=" crossorigin="anonymous"></script> <script defer src="/assets/js/chartjs-setup.js?183c5859923724fb1cb3c67593848e71" type="text/javascript"></script> <script src="https://cdn.jsdelivr.net/npm/echarts@5.5.0/dist/echarts.min.js" integrity="sha256-QvgynZibb2U53SsVu98NggJXYqwRL7tg3FeyfXvPOUY=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/echarts@5.5.0/theme/dark-fresh-cut.js" integrity="sha256-sm6Ui9w41++ZCWmIWDLC18a6ki72FQpWDiYTDxEPXwU=" crossorigin="anonymous"></script> <script defer src="/assets/js/echarts-setup.js?738178999630746a8d0cfc261fc47c2c" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/vega@5.27.0/build/vega.min.js" integrity="sha256-Yot/cfgMMMpFwkp/5azR20Tfkt24PFqQ6IQS+80HIZs=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/vega-lite@5.16.3/build/vega-lite.min.js" integrity="sha256-TvBvIS5jUN4BSy009usRjNzjI1qRrHPYv7xVLJyjUyw=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/vega-embed@6.24.0/build/vega-embed.min.js" integrity="sha256-FPCJ9JYCC9AZSpvC/t/wHBX7ybueZhIqOMjpWqfl3DU=" crossorigin="anonymous"></script> <script defer src="/assets/js/vega-setup.js?7c7bee055efe9312afc861b128fe5f36" type="text/javascript"></script> <script defer src="https://tikzjax.com/v1/tikzjax.js" integrity="sha256-+1qyucCXRZJrCg3lm3KxRt/7WXaYhBid4/1XJRHGB1E=" crossorigin="anonymous"></script> <script src="/assets/js/typograms.js?062e75bede72543443762dc3fe36c7a5"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>